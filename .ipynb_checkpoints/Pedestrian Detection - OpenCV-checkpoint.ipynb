{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] images\\image_1.jpg: 0 original boxes, 0 after suppression\n",
      "[INFO] images\\image_2.jpg: 0 original boxes, 0 after suppression\n",
      "[INFO] images\\image_3.jpg: 0 original boxes, 0 after suppression\n",
      "[INFO] images\\image_4.jpg: 1 original boxes, 1 after suppression\n",
      "[INFO] images\\image_5.jpg: 1 original boxes, 1 after suppression\n",
      "[INFO] images\\image_6.jpg: 1 original boxes, 1 after suppression\n",
      "[INFO] images\\image_7.jpg: 1 original boxes, 1 after suppression\n",
      "[INFO] images\\image_8.jpg: 1 original boxes, 1 after suppression\n",
      "[INFO] images\\image_9.jpg: 1 original boxes, 1 after suppression\n",
      "[INFO] images\\image_10.jpg: 0 original boxes, 0 after suppression\n",
      "[INFO] images\\image_11.jpg: 0 original boxes, 0 after suppression\n",
      "[INFO] images\\image_12.jpg: 1 original boxes, 1 after suppression\n",
      "[INFO] images\\image_13.jpg: 0 original boxes, 0 after suppression\n",
      "[INFO] images\\image_14.jpg: 0 original boxes, 0 after suppression\n",
      "[INFO] images\\image_15.jpg: 0 original boxes, 0 after suppression\n"
     ]
    }
   ],
   "source": [
    "# Reading frames from the video file, though in our main implementation we'll be using camera for our video feed\n",
    "# here we'll be reading from the video file\n",
    "video_file = cv2.VideoCapture('pedestrian2.mp4')\n",
    "# now we will make sure that the file is not corrupted\n",
    "if video_file.isOpened() == False:\n",
    "    print(\"Couldn't open the file, it may be corrupted\")\n",
    "# otherwise we will look for all the frames till end, but instead of working on each and every frame\n",
    "# we will only apply our model to reduced number of frames to improve the time complexity\n",
    "frame_rate = video_file.get(2)\n",
    "count = 0 # this is to name files based on counter\n",
    "foldername = 'images'\n",
    "while(video_file.isOpened):\n",
    "    # capture frames\n",
    "    ret, frame = video_file.read()\n",
    "    # get to know about the frame_id\n",
    "    frame_id = video_file.get(1)\n",
    "    if ret == False:\n",
    "        # we met some error, break\n",
    "        break\n",
    "    # otherwise select only 5 frames in 1 sec instead of all the frames i.e 24 or 30 depending upon the fps\n",
    "    if frame_id % math.floor(frame_rate) == 0:\n",
    "        # feed this frame to our model and extract the information\n",
    "        # but before that we will save the frames also in order to verify whether our model is working correctly or not\n",
    "        count += 1\n",
    "        filepath = foldername + \"\\image_\"+str(count)+\".jpg\"\n",
    "        # save it\n",
    "        cv2.imwrite(filepath, frame)\n",
    "        get_pedestrian(filepath)\n",
    "video_file.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pedestrian(filepath):\n",
    "    '''\n",
    "    This function will analyze the image provided its path, the number of pedestrian present in the image\n",
    "    and output the result to a file called information.txt\n",
    "    '''\n",
    "    image = cv2.imread(filepath)\n",
    "    image = imutils.resize(image, width=min(400, image.shape[1]))\n",
    "    orig = image.copy()\n",
    "    \n",
    "    # detect the people in image\n",
    "    (rects, weights) = hog.detectMultiScale(image, winStride=(4, 4), padding=(8, 8), scale=1.05)\n",
    "    # rect will contain h, w, x, y which can be used to form the rectange and weights are the confidence level of the classifier\n",
    "    # draw the bounding boxes using the coordinates\n",
    "    for (x, y, w, h) in rects:\n",
    "        cv2.rectangle(orig, (x, y), (x + w, y + h), color=(0, 0, 255), thickness=2)\n",
    "    \n",
    "    # Now we'll applying NMS to get rid of redundant bounding boxes\n",
    "    rects = np.array([[x, y, (x + w), (y + h)] for x, y, w, h in rects])\n",
    "    # in this we will pick only one boundin box\n",
    "    pick = non_max_suppression(rects, probs=None, overlapThresh=0.65 )\n",
    "    \n",
    "    # now draw the final bounding box that we have in pick\n",
    "    for x_a, y_a, x_b, y_b in pick:\n",
    "        cv2.rectangle(image, (x_a, y_a), (x_b, y_b), (0, 255, 0), 2)\n",
    "    # show some information on the number of bounding boxes\n",
    "    filename = filepath[filepath.rfind(\"/\") + 1:]\n",
    "    print(\"[INFO] {}: {} original boxes, {} after suppression\".format(\n",
    "    filename, len(rects), len(pick)))\n",
    "    # How about writing this information in a textfile\n",
    "    f = open('Information.txt', 'a')\n",
    "    f.write(\"\\nPedestrian detected in image-\" + str(count) +\" is \" + str(len(pick)))\n",
    "    f.close()\n",
    "    \n",
    "    new_filepath = \"detected\\images_\" + str(count) + \".jpg\"\n",
    "    cv2.imwrite(new_filepath, image)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
